{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abba5897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rayarawajba/miniconda3/envs/nlp-classification-v01/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import torch\n",
    "import re\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29745c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/rayarawajba/.cache/kagglehub/datasets/muhammadimran112233/liar-twitter-dataset/versions/1\n"
     ]
    }
   ],
   "source": [
    "# Download dataset from Kaggle\n",
    "path = kagglehub.dataset_download(\"muhammadimran112233/liar-twitter-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d7aace8",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Introduction:\n",
    "# The following code demonstrates how to process and batch text data for a poem classification task using PyTorch.\n",
    "# It covers loading and preprocessing the dataset, tokenizing and numericalizing the text, creating a custom Dataset,\n",
    "# and batching the data with padding for use in neural network models. This setup is essential for training\n",
    "# deep learning models on variable-length text sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f38a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully.\n",
      "    [ID].json       label                                          statement  \\\n",
      "0  11972.json        TRUE  Building a wall on the U.S.-Mexico border will...   \n",
      "1  11685.json       FALSE  Wisconsin is on pace to double the number of l...   \n",
      "2  11096.json       FALSE  Says John McCain has done nothing to help the ...   \n",
      "3   5209.json   half-true  Suzanne Bonamici supports a plan that will cut...   \n",
      "4   9524.json  pants-fire  When asked by a reporter whether hes at the ce...   \n",
      "\n",
      "                                          subject(s)  \\\n",
      "0                                        immigration   \n",
      "1                                               jobs   \n",
      "2                    military,veterans,voting-record   \n",
      "3  medicare,message-machine-2012,campaign-adverti...   \n",
      "4  campaign-finance,legal-issues,campaign-adverti...   \n",
      "\n",
      "                            speaker   speaker's job title state info  \\\n",
      "0                        rick-perry              Governor      Texas   \n",
      "1                 katrina-shankland  State representative  Wisconsin   \n",
      "2                      donald-trump       President-Elect   New York   \n",
      "3                     rob-cornilles            consultant     Oregon   \n",
      "4  state-democratic-party-wisconsin                   NaN  Wisconsin   \n",
      "\n",
      "  party affiliation  barely true counts  false counts  half true counts  \\\n",
      "0        republican                  30            30                42   \n",
      "1          democrat                   2             1                 0   \n",
      "2        republican                  63           114                51   \n",
      "3        republican                   1             1                 3   \n",
      "4          democrat                   5             7                 2   \n",
      "\n",
      "   mostly true counts  pants on fire counts                         venue  \n",
      "0                  23                    18               Radio interview  \n",
      "1                   0                     0             a news conference  \n",
      "2                  37                    61  comments on ABC's This Week.  \n",
      "3                   1                     1                  a radio show  \n",
      "4                   2                     7                   a web video  \n"
     ]
    }
   ],
   "source": [
    "# Load the training dataset into a DataFrame\n",
    "df = pd.read_csv(path + \"/Liar_Dataset.csv\")\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "print(df.head())  # Display the first few rows of the dataset\n",
    "# count_label_0 = df['label'].value_counts().get(TRUE, 0)\n",
    "# count_label_1 = df['label'].value_counts().get(FALSE, 0)\n",
    "# print(\"Number of items with label = 0:\", count_label_0)\n",
    "# print(\"Number of items with label = 1:\", count_label_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f731033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12787 entries, 0 to 12786\n",
      "Data columns (total 14 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   [ID].json             12787 non-null  object\n",
      " 1   label                 12787 non-null  object\n",
      " 2   statement             12787 non-null  object\n",
      " 3   subject(s)            12787 non-null  object\n",
      " 4   speaker               12787 non-null  object\n",
      " 5   speaker's job title   9221 non-null   object\n",
      " 6   state info            10038 non-null  object\n",
      " 7   party affiliation     12787 non-null  object\n",
      " 8   barely true counts    12787 non-null  int64 \n",
      " 9   false counts          12787 non-null  int64 \n",
      " 10  half true counts      12787 non-null  int64 \n",
      " 11  mostly true counts    12787 non-null  int64 \n",
      " 12  pants on fire counts  12787 non-null  int64 \n",
      " 13  venue                 12658 non-null  object\n",
      "dtypes: int64(5), object(9)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "       barely true counts  false counts  half true counts  mostly true counts  \\\n",
      "count        12787.000000  12787.000000      12787.000000        12787.000000   \n",
      "mean            11.585673     13.361070         17.188394           16.500430   \n",
      "std             18.979013     24.141438         35.849874           36.167516   \n",
      "min              0.000000      0.000000          0.000000            0.000000   \n",
      "25%              0.000000      0.000000          0.000000            0.000000   \n",
      "50%              2.000000      2.000000          3.000000            3.000000   \n",
      "75%             12.000000     15.000000         13.000000           12.000000   \n",
      "max             70.000000    114.000000        160.000000          163.000000   \n",
      "\n",
      "       pants on fire counts  \n",
      "count          12787.000000  \n",
      "mean               6.252366  \n",
      "std               16.181854  \n",
      "min                0.000000  \n",
      "25%                0.000000  \n",
      "50%                1.000000  \n",
      "75%                5.000000  \n",
      "max              105.000000  \n",
      "Index(['[ID].json', 'label', 'statement', 'subject(s)', 'speaker',\n",
      "       'speaker's job title', 'state info', 'party affiliation',\n",
      "       'barely true counts', 'false counts', 'half true counts',\n",
      "       'mostly true counts', 'pants on fire counts', 'venue'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Explore the dataset\n",
    "print(df.info())\n",
    "print(df.describe())\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50b2ded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/rayarawajba/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/rayarawajba/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/rayarawajba/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/rayarawajba/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc5e6b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess text data\n",
    "def preprocess_text(text):\n",
    "    try:\n",
    "        # Check if text is not NaN and is a string\n",
    "        if isinstance(text, str):\n",
    "            # Remove leading and trailing whitespace\n",
    "            text = text.strip()\n",
    "            # Remove HTML tags\n",
    "            text = re.sub(r'<.*?>', '', text)\n",
    "            # Remove URLs\n",
    "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "            # Remove email addresses\n",
    "            text = re.sub(r'\\S+@\\S+', '', text)\n",
    "            # Remove non-ASCII characters\n",
    "            text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "            # Remove extra whitespace\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            # Remove digits\n",
    "            text = re.sub(r'\\d+', '', text)\n",
    "            # Remove leading and trailing whitespace again\n",
    "            text = text.strip()\n",
    "            # Remove special characters\n",
    "            text = re.sub(r'[^\\w\\s]', '', text)\n",
    "            # Remove extra spaces\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            # Remove single characters\n",
    "            text = re.sub(r'\\b\\w\\b', '', text)\n",
    "            # Convert to lowercase\n",
    "            text = text.lower()\n",
    "            # Remove punctuation\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "            # Tokenize the text\n",
    "            tokens = word_tokenize(text)\n",
    "            # Remove stopwords\n",
    "            stop_words = set(stopwords.words('english'))\n",
    "            tokens = [word for word in tokens if word not in stop_words]\n",
    "            # Remove numbers\n",
    "            tokens = [word for word in tokens if not word.isdigit()]\n",
    "            # Remove extra spaces\n",
    "            text = ' '.join(tokens)\n",
    "            # Remove special characters\n",
    "            text = re.sub(r'\\W+', ' ', text)\n",
    "        else:\n",
    "            text = \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text: {text}. Error: {e}\")\n",
    "        text = \"\"\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd55fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete. Sample preprocessed data:\n",
      "0    building wall usmexico border take literally y...\n",
      "1            wisconsin pace double number layoffs year\n",
      "2              says john mccain done nothing help vets\n",
      "3    suzanne bonamici supports plan cut choice medi...\n",
      "4    asked reporter whether hes center criminal sch...\n",
      "Name: statement, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the dataset\n",
    "preprocessed_df = df.copy()\n",
    "preprocessed_df['statement'] = preprocessed_df['statement'].apply(preprocess_text)\n",
    "print(\"Preprocessing complete. Sample preprocessed data:\")\n",
    "print(preprocessed_df['statement'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15b46adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization complete. Sample tokens:\n",
      "0    [building, wall, usmexico, border, take, liter...\n",
      "1     [wisconsin, pace, double, number, layoffs, year]\n",
      "2      [says, john, mccain, done, nothing, help, vets]\n",
      "3    [suzanne, bonamici, supports, plan, cut, choic...\n",
      "4    [asked, reporter, whether, hes, center, crimin...\n",
      "Name: Tokens, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the preprocessed text\n",
    "preprocessed_df['Tokens'] = preprocessed_df['statement'].apply(word_tokenize)\n",
    "print(\"Tokenization complete. Sample tokens:\")\n",
    "print(preprocessed_df['Tokens'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a552844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens in dataset: 134804\n"
     ]
    }
   ],
   "source": [
    "# Count the total number of tokens in the dataset\n",
    "tokens = []\n",
    "for token_list in preprocessed_df['Tokens']:\n",
    "    tokens.extend(token_list)\n",
    "print(\"Total tokens in dataset:\", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75beff0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 13669\n"
     ]
    }
   ],
   "source": [
    "unique_tokens = list(set(tokens)) # Sorting here is optional but ensures consistent ID assignment\n",
    "PAD_ID = 0\n",
    "UNK_ID = 1\n",
    "# Create a mapping from tokens to IDs\n",
    "# This mapping will be used to convert tokens to numerical IDs for model input\n",
    "# Ensure that special tokens are included in the mapping\n",
    "word_to_id = {\"<pad>\": PAD_ID, \"<unk>\": UNK_ID} # Special token IDs\n",
    "next_id = 2 \n",
    "\n",
    "for token in unique_tokens:\n",
    "    if token not in word_to_id: # Ensure special tokens are not overwritten if they happen to be in the text\n",
    "        word_to_id[token] = next_id\n",
    "        next_id += 1\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "print(f\"Vocabulary Size: {vocab_size}\")\n",
    "# print(word_to_id)\n",
    "\n",
    "# id_to_word mapping for debugging/reverse lookup\n",
    "id_to_word = {v: k for k, v in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "685d2079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'FALSE': 0, 'TRUE': 1, 'barely-true': 2, 'half-true': 3, 'mostly-true': 4, 'pants-fire': 5}\n"
     ]
    }
   ],
   "source": [
    "preprocessed_df['Numerical_Tokens'] = preprocessed_df['Tokens'].apply(\n",
    "    lambda token_list: [word_to_id.get(token, word_to_id[\"<unk>\"]) for token in token_list]\n",
    ")\n",
    "\n",
    "\n",
    "#  Numericalize the 'Label' column in the DataFrame ---\n",
    "# Get all unique labels\n",
    "unique_labels = sorted(preprocessed_df['label'].unique().tolist()) \n",
    "# unique_labels = ['fake', 'true']  \n",
    "# label_to_id = {'fake': 0, 'true': 1}\n",
    "# id_to_label = {0: 'fake', 1: 'true'}\n",
    "\n",
    "# Create a mapping from string label to integer ID\n",
    "label_to_id = {label: i for i, label in enumerate(unique_labels)}\n",
    "print(label_to_id)\n",
    "# Create a mapping from integer ID to string label\n",
    "id_to_label = {i: label for label, i in label_to_id.items()}\n",
    "num_classes = len(label_to_id)\n",
    "\n",
    "preprocessed_df['Numerical_Label'] = preprocessed_df['label'].map(label_to_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae54ec4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, numerical_tokens, numerical_labels):\n",
    "        self.numerical_tokens = numerical_tokens\n",
    "        self.numerical_labels = numerical_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.numerical_tokens)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return numerical tokens as a PyTorch tensor and the label\n",
    "        # We convert to tensor here, but padding happens in collate_fn\n",
    "        token_ids = torch.tensor(self.numerical_tokens.iloc[idx], dtype=torch.long)\n",
    "        label = torch.tensor(self.numerical_labels.iloc[idx], dtype=torch.long)\n",
    "        return token_ids, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03af1eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [3, 4, 5]  # Example kernel sizes for CNN\n",
    "min_required_seq_len = max(kernel_sizes)  # Define this based on your model's kernel sizes\n",
    "def collate_fn(batch):\n",
    "    # Assume min_required_seq_len is defined in your context (e.g. globally, or as a param)\n",
    "    # e.g., min_required_seq_len = max(model.kernel_sizes)\n",
    "\n",
    "    # Separate token IDs and labels\n",
    "    token_ids_list = [item[0] for item in batch]\n",
    "    labels_list = [item[1] for item in batch]\n",
    "\n",
    "    # First, ensure each token_ids is at least min_required_seq_len long\n",
    "    adjusted_token_ids_list = []\n",
    "    for seq in token_ids_list:\n",
    "        if len(seq) < min_required_seq_len:\n",
    "            pad = torch.full((min_required_seq_len - len(seq),), PAD_ID, dtype=seq.dtype)\n",
    "            seq = torch.cat([seq, pad], dim=0)\n",
    "        adjusted_token_ids_list.append(seq)\n",
    "\n",
    "    # Now pad all to batch max length (could be > min_required_seq_len!)\n",
    "    padded_token_ids = pad_sequence(adjusted_token_ids_list,\n",
    "                                   batch_first=True,\n",
    "                                   padding_value=PAD_ID) \n",
    "\n",
    "    # Stack labels into a single tensor\n",
    "    labels = torch.stack(labels_list)\n",
    "\n",
    "    return padded_token_ids, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "838a203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    preprocessed_df,\n",
    "    test_size=0.2,    # 20% for testing\n",
    "    random_state=42,  # A common seed for reproducibility\n",
    "    stratify=preprocessed_df['label'] # Stratify by the original string label column for balanced splits\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "11c9a82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_df['Numerical_Tokens'], train_df['Numerical_Label'])\n",
    "test_dataset = TextDataset(test_df['Numerical_Tokens'], test_df['Numerical_Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30507e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataLoader created with batch_size=4. Iterating through a few batches:\n",
      "\n",
      "--- Batch 1 ---\n",
      "Padded Token IDs (shape, content):\n",
      "torch.Size([4, 14])\n",
      "tensor([[  118,  7110,  8900,  5402, 12407,  6090,  3263,     0,     0,     0,\n",
      "             0,     0,     0,     0],\n",
      "        [ 2617,  4834,  1243,  7493,  2256, 10992,  3474,  7345,  9205,  1224,\n",
      "         10414,     0,     0,     0],\n",
      "        [13147,  2745,  5316,  2151,  8009,  4751, 13083,  3309,  3205,  4816,\n",
      "          6778,  7139,  7256, 13378],\n",
      "        [ 8904,   696,  6757, 10799,  5406,  4352,  3086, 12845,  4401,  6150,\n",
      "           510,     0,     0,     0]])\n",
      "Labels (shape, content):\n",
      "torch.Size([4])\n",
      "tensor([4, 2, 0, 3])\n",
      "\n",
      "--- Batch 2 ---\n",
      "Padded Token IDs (shape, content):\n",
      "torch.Size([4, 13])\n",
      "tensor([[ 2106,  9069,  3319, 12392, 12628,  7110, 12283, 11233,  5424,     0,\n",
      "             0,     0,     0],\n",
      "        [10806, 11216,   759,   962,  1455,  8721, 12386, 12699,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [13147, 10449,  9944,  6301, 11839, 11342,  5641, 12447,     0,     0,\n",
      "             0,     0,     0],\n",
      "        [ 3019,  5402, 11871, 12050,  5901,  9250, 11063,  4296,  2483,  7804,\n",
      "          5813, 11604, 12285]])\n",
      "Labels (shape, content):\n",
      "torch.Size([4])\n",
      "tensor([1, 1, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 4 # Choose your batch size\n",
    "train_dataloader = DataLoader(train_dataset,\n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True, # Shuffle for training\n",
    "                        collate_fn=collate_fn)\n",
    "\n",
    "print(f\"\\nDataLoader created with batch_size={batch_size}. Iterating through a few batches:\")\n",
    "\n",
    "# --- 4. Iterate through the DataLoader to see the padded batches ---\n",
    "for i, (batch_tokens, batch_labels) in enumerate(train_dataloader):\n",
    "    print(f\"\\n--- Batch {i+1} ---\")\n",
    "    print(\"Padded Token IDs (shape, content):\")\n",
    "    print(batch_tokens.shape)\n",
    "    print(batch_tokens)\n",
    "    print(\"Labels (shape, content):\")\n",
    "    print(batch_labels.shape)\n",
    "    print(batch_labels)\n",
    "\n",
    "    if i >= 1: # Just show a couple of batches\n",
    "        break\n",
    "\n",
    "# This `batch_tokens` tensor (e.g., shape [batch_size, max_seq_len_in_batch])\n",
    "# is what you directly feed into your PyTorch nn.Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4de7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, num_classes, pad_idx):\n",
    "        super(TextCNN, self).__init__()\n",
    "\n",
    "        # 1. Embedding Layer\n",
    "        # pad_idx tells the embedding layer to not update the embedding for this index (PAD_ID)\n",
    "        # and it will output zeros for that index.\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "\n",
    "        # 2. Convolutional Layers \n",
    "        self.kernel_sizes = [3, 4, 5] # Example: capture 3-gram, 4-gram, 5-gram features\n",
    "        self.num_filters = 100        # Number of filters (feature detectors) per kernel size\n",
    "\n",
    "        self.convs = nn.ModuleList([\n",
    "            nn.Conv1d(in_channels=embedding_dim, # Input channels are the embedding dimension\n",
    "                      out_channels=self.num_filters,\n",
    "                      kernel_size=k)\n",
    "            for k in self.kernel_sizes\n",
    "        ])\n",
    "\n",
    "        # 3. Fully Connected (Dense) Layer for classification\n",
    "        # Sum of num_filters for each kernel size, as we concatenate their outputs\n",
    "        self.fc = nn.Linear(len(self.kernel_sizes) * self.num_filters, num_classes)\n",
    "\n",
    "        # Dropout for regularization (to prevent overfitting)\n",
    "        self.dropout = nn.Dropout(0.5) # Example dropout rate\n",
    "\n",
    "    def forward(self, text):\n",
    "        # text shape: (batch_size, sequence_length)\n",
    "\n",
    "        # Pass through embedding layer\n",
    "        embedded = self.embedding(text)\n",
    "        # embedded shape: (batch_size, sequence_length, embedding_dim)\n",
    "\n",
    "        # PyTorch Conv1d expects input in (batch_size, channels, sequence_length)\n",
    "        # So we permute the dimensions\n",
    "        embedded = embedded.permute(0, 2, 1)\n",
    "        # embedded shape: (batch_size, embedding_dim, sequence_length)\n",
    "\n",
    "        # Apply convolutions and ReLU activation\n",
    "        # For each conv layer, apply it, then apply ReLU, then apply global max pooling\n",
    "        # The pooling operation extracts the most important feature from each filter's output\n",
    "        conved = [F.relu(conv(embedded)) for conv in self.convs]\n",
    "        # conved[i] shape: (batch_size, num_filters, output_sequence_length)\n",
    "\n",
    "        # Apply global max pooling over the sequence dimension\n",
    "        # This takes the maximum value from each filter's output across the entire sequence\n",
    "        pooled = [F.max_pool1d(c, c.shape[2]).squeeze(2) for c in conved]\n",
    "        # pooled[i] shape: (batch_size, num_filters)\n",
    "\n",
    "        # Concatenate the pooled outputs from all kernel sizes\n",
    "        cat = self.dropout(torch.cat(pooled, dim=1))\n",
    "        # cat shape: (batch_size, num_filters * len(kernel_sizes))\n",
    "\n",
    "        # Pass through the fully connected layer\n",
    "        output = self.fc(cat)\n",
    "        # output shape: (batch_size, num_classes)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81d7503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "embedding_dim = 50 \n",
    "model = TextCNN(vocab_size, embedding_dim, num_classes, PAD_ID)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1632b4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train() # Set model to training mode\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad() # Clear previous gradients\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d61856da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.693548 [    4/10229]\n",
      "loss: 2.288349 [  404/10229]\n",
      "loss: 2.215557 [  804/10229]\n",
      "loss: 2.210623 [ 1204/10229]\n",
      "loss: 2.546705 [ 1604/10229]\n",
      "loss: 1.176772 [ 2004/10229]\n",
      "loss: 1.731690 [ 2404/10229]\n",
      "loss: 1.651572 [ 2804/10229]\n",
      "loss: 2.712379 [ 3204/10229]\n",
      "loss: 2.136947 [ 3604/10229]\n",
      "loss: 3.821948 [ 4004/10229]\n",
      "loss: 1.969606 [ 4404/10229]\n",
      "loss: 1.749651 [ 4804/10229]\n",
      "loss: 1.681575 [ 5204/10229]\n",
      "loss: 3.037511 [ 5604/10229]\n",
      "loss: 2.095672 [ 6004/10229]\n",
      "loss: 1.766688 [ 6404/10229]\n",
      "loss: 1.728169 [ 6804/10229]\n",
      "loss: 2.288031 [ 7204/10229]\n",
      "loss: 1.140062 [ 7604/10229]\n",
      "loss: 2.990820 [ 8004/10229]\n",
      "loss: 2.337970 [ 8404/10229]\n",
      "loss: 1.420963 [ 8804/10229]\n",
      "loss: 2.042612 [ 9204/10229]\n",
      "loss: 2.419693 [ 9604/10229]\n",
      "loss: 1.982548 [10004/10229]\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 3.155347 [    4/10229]\n",
      "loss: 2.978479 [  404/10229]\n",
      "loss: 3.180850 [  804/10229]\n",
      "loss: 2.707742 [ 1204/10229]\n",
      "loss: 2.768564 [ 1604/10229]\n",
      "loss: 1.818096 [ 2004/10229]\n",
      "loss: 1.532067 [ 2404/10229]\n",
      "loss: 1.596276 [ 2804/10229]\n",
      "loss: 2.972032 [ 3204/10229]\n",
      "loss: 1.514803 [ 3604/10229]\n",
      "loss: 2.988811 [ 4004/10229]\n",
      "loss: 2.287097 [ 4404/10229]\n",
      "loss: 2.987412 [ 4804/10229]\n",
      "loss: 1.763556 [ 5204/10229]\n",
      "loss: 1.932685 [ 5604/10229]\n",
      "loss: 1.272191 [ 6004/10229]\n",
      "loss: 2.382070 [ 6404/10229]\n",
      "loss: 3.519433 [ 6804/10229]\n",
      "loss: 3.935890 [ 7204/10229]\n",
      "loss: 1.797255 [ 7604/10229]\n",
      "loss: 2.501495 [ 8004/10229]\n",
      "loss: 1.919003 [ 8404/10229]\n",
      "loss: 1.816227 [ 8804/10229]\n",
      "loss: 2.381972 [ 9204/10229]\n",
      "loss: 4.767248 [ 9604/10229]\n",
      "loss: 2.643494 [10004/10229]\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 3.472658 [    4/10229]\n",
      "loss: 1.352956 [  404/10229]\n",
      "loss: 1.177208 [  804/10229]\n",
      "loss: 3.489035 [ 1204/10229]\n",
      "loss: 1.541850 [ 1604/10229]\n",
      "loss: 0.934197 [ 2004/10229]\n",
      "loss: 0.703751 [ 2404/10229]\n",
      "loss: 2.224355 [ 2804/10229]\n",
      "loss: 2.292228 [ 3204/10229]\n",
      "loss: 2.354664 [ 3604/10229]\n",
      "loss: 1.697594 [ 4004/10229]\n",
      "loss: 2.805118 [ 4404/10229]\n",
      "loss: 3.161436 [ 4804/10229]\n",
      "loss: 3.556428 [ 5204/10229]\n",
      "loss: 2.634331 [ 5604/10229]\n",
      "loss: 2.937236 [ 6004/10229]\n",
      "loss: 1.914994 [ 6404/10229]\n",
      "loss: 1.964396 [ 6804/10229]\n",
      "loss: 2.969123 [ 7204/10229]\n",
      "loss: 2.686098 [ 7604/10229]\n",
      "loss: 1.916950 [ 8004/10229]\n",
      "loss: 1.456277 [ 8404/10229]\n",
      "loss: 2.976866 [ 8804/10229]\n",
      "loss: 1.798464 [ 9204/10229]\n",
      "loss: 2.054203 [ 9604/10229]\n",
      "loss: 2.120888 [10004/10229]\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 4.267358 [    4/10229]\n",
      "loss: 5.342901 [  404/10229]\n",
      "loss: 3.144110 [  804/10229]\n",
      "loss: 0.988567 [ 1204/10229]\n",
      "loss: 1.540634 [ 1604/10229]\n",
      "loss: 1.685183 [ 2004/10229]\n",
      "loss: 3.358762 [ 2404/10229]\n",
      "loss: 3.421710 [ 2804/10229]\n",
      "loss: 1.937799 [ 3204/10229]\n",
      "loss: 1.210290 [ 3604/10229]\n",
      "loss: 0.661068 [ 4004/10229]\n",
      "loss: 1.321491 [ 4404/10229]\n",
      "loss: 3.198690 [ 4804/10229]\n",
      "loss: 1.564817 [ 5204/10229]\n",
      "loss: 1.257201 [ 5604/10229]\n",
      "loss: 2.742595 [ 6004/10229]\n",
      "loss: 4.406992 [ 6404/10229]\n",
      "loss: 2.308313 [ 6804/10229]\n",
      "loss: 2.256005 [ 7204/10229]\n",
      "loss: 2.137898 [ 7604/10229]\n",
      "loss: 3.288841 [ 8004/10229]\n",
      "loss: 0.878256 [ 8404/10229]\n",
      "loss: 1.250152 [ 8804/10229]\n",
      "loss: 3.312640 [ 9204/10229]\n",
      "loss: 4.653273 [ 9604/10229]\n",
      "loss: 3.787202 [10004/10229]\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.895238 [    4/10229]\n",
      "loss: 1.733153 [  404/10229]\n",
      "loss: 3.372262 [  804/10229]\n",
      "loss: 2.322381 [ 1204/10229]\n",
      "loss: 3.838149 [ 1604/10229]\n",
      "loss: 3.510312 [ 2004/10229]\n",
      "loss: 3.021847 [ 2404/10229]\n",
      "loss: 1.762331 [ 2804/10229]\n",
      "loss: 1.519208 [ 3204/10229]\n",
      "loss: 2.097435 [ 3604/10229]\n",
      "loss: 4.706211 [ 4004/10229]\n",
      "loss: 2.746664 [ 4404/10229]\n",
      "loss: 1.733794 [ 4804/10229]\n",
      "loss: 1.019854 [ 5204/10229]\n",
      "loss: 2.305655 [ 5604/10229]\n",
      "loss: 1.118731 [ 6004/10229]\n",
      "loss: 2.049606 [ 6404/10229]\n",
      "loss: 1.446720 [ 6804/10229]\n",
      "loss: 5.408000 [ 7204/10229]\n",
      "loss: 4.092975 [ 7604/10229]\n",
      "loss: 4.620070 [ 8004/10229]\n",
      "loss: 3.009806 [ 8404/10229]\n",
      "loss: 3.401669 [ 8804/10229]\n",
      "loss: 0.708750 [ 9204/10229]\n",
      "loss: 2.083939 [ 9604/10229]\n",
      "loss: 6.216357 [10004/10229]\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 1.739637 [    4/10229]\n",
      "loss: 5.489776 [  404/10229]\n",
      "loss: 0.995173 [  804/10229]\n",
      "loss: 1.859901 [ 1204/10229]\n",
      "loss: 2.768825 [ 1604/10229]\n",
      "loss: 3.272079 [ 2004/10229]\n",
      "loss: 6.317307 [ 2404/10229]\n",
      "loss: 0.742371 [ 2804/10229]\n",
      "loss: 3.326100 [ 3204/10229]\n",
      "loss: 2.201808 [ 3604/10229]\n",
      "loss: 8.496188 [ 4004/10229]\n",
      "loss: 3.776479 [ 4404/10229]\n",
      "loss: 2.473744 [ 4804/10229]\n",
      "loss: 5.515625 [ 5204/10229]\n",
      "loss: 5.319689 [ 5604/10229]\n",
      "loss: 1.669470 [ 6004/10229]\n",
      "loss: 5.624514 [ 6404/10229]\n",
      "loss: 10.180906 [ 6804/10229]\n",
      "loss: 3.974284 [ 7204/10229]\n",
      "loss: 0.658579 [ 7604/10229]\n",
      "loss: 3.797911 [ 8004/10229]\n",
      "loss: 3.537416 [ 8404/10229]\n",
      "loss: 2.081318 [ 8804/10229]\n",
      "loss: 3.680836 [ 9204/10229]\n",
      "loss: 1.445002 [ 9604/10229]\n",
      "loss: 5.759724 [10004/10229]\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 2.749828 [    4/10229]\n",
      "loss: 6.120457 [  404/10229]\n",
      "loss: 2.304378 [  804/10229]\n",
      "loss: 3.011153 [ 1204/10229]\n",
      "loss: 1.375017 [ 1604/10229]\n",
      "loss: 3.047608 [ 2004/10229]\n",
      "loss: 1.505444 [ 2404/10229]\n",
      "loss: 2.494161 [ 2804/10229]\n",
      "loss: 5.485729 [ 3204/10229]\n",
      "loss: 3.999693 [ 3604/10229]\n",
      "loss: 6.973177 [ 4004/10229]\n",
      "loss: 2.804271 [ 4404/10229]\n",
      "loss: 1.842430 [ 4804/10229]\n",
      "loss: 0.932173 [ 5204/10229]\n",
      "loss: 4.194904 [ 5604/10229]\n",
      "loss: 6.653066 [ 6004/10229]\n",
      "loss: 6.002677 [ 6404/10229]\n",
      "loss: 1.457788 [ 6804/10229]\n",
      "loss: 1.534451 [ 7204/10229]\n",
      "loss: 6.255946 [ 7604/10229]\n",
      "loss: 5.689175 [ 8004/10229]\n",
      "loss: 1.937999 [ 8404/10229]\n",
      "loss: 6.050874 [ 8804/10229]\n",
      "loss: 2.708420 [ 9204/10229]\n",
      "loss: 4.529790 [ 9604/10229]\n",
      "loss: 4.150956 [10004/10229]\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 2.377507 [    4/10229]\n",
      "loss: 3.826214 [  404/10229]\n",
      "loss: 2.728793 [  804/10229]\n",
      "loss: 3.244854 [ 1204/10229]\n",
      "loss: 1.102686 [ 1604/10229]\n",
      "loss: 1.986182 [ 2004/10229]\n",
      "loss: 3.478374 [ 2404/10229]\n",
      "loss: 2.443338 [ 2804/10229]\n",
      "loss: 4.276812 [ 3204/10229]\n",
      "loss: 8.460695 [ 3604/10229]\n",
      "loss: 2.159354 [ 4004/10229]\n",
      "loss: 5.767028 [ 4404/10229]\n",
      "loss: 5.634181 [ 4804/10229]\n",
      "loss: 1.587925 [ 5204/10229]\n",
      "loss: 0.012242 [ 5604/10229]\n",
      "loss: 2.652988 [ 6004/10229]\n",
      "loss: 6.694919 [ 6404/10229]\n",
      "loss: 0.853627 [ 6804/10229]\n",
      "loss: 0.355252 [ 7204/10229]\n",
      "loss: 6.411535 [ 7604/10229]\n",
      "loss: 5.042129 [ 8004/10229]\n",
      "loss: 4.965285 [ 8404/10229]\n",
      "loss: 3.575057 [ 8804/10229]\n",
      "loss: 0.898312 [ 9204/10229]\n",
      "loss: 4.389682 [ 9604/10229]\n",
      "loss: 6.128924 [10004/10229]\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 6.749027 [    4/10229]\n",
      "loss: 0.638055 [  404/10229]\n",
      "loss: 2.652173 [  804/10229]\n",
      "loss: 1.012883 [ 1204/10229]\n",
      "loss: 1.300111 [ 1604/10229]\n",
      "loss: 1.855052 [ 2004/10229]\n",
      "loss: 4.555532 [ 2404/10229]\n",
      "loss: 2.126860 [ 2804/10229]\n",
      "loss: 0.143928 [ 3204/10229]\n",
      "loss: 1.296774 [ 3604/10229]\n",
      "loss: 1.599255 [ 4004/10229]\n",
      "loss: 2.546544 [ 4404/10229]\n",
      "loss: 6.820323 [ 4804/10229]\n",
      "loss: 1.076710 [ 5204/10229]\n",
      "loss: 0.931575 [ 5604/10229]\n",
      "loss: 3.006006 [ 6004/10229]\n",
      "loss: 1.112928 [ 6404/10229]\n",
      "loss: 1.928151 [ 6804/10229]\n",
      "loss: 9.808405 [ 7204/10229]\n",
      "loss: 6.065212 [ 7604/10229]\n",
      "loss: 11.178893 [ 8004/10229]\n",
      "loss: 4.670713 [ 8404/10229]\n",
      "loss: 5.434486 [ 8804/10229]\n",
      "loss: 1.264603 [ 9204/10229]\n",
      "loss: 1.625404 [ 9604/10229]\n",
      "loss: 5.197279 [10004/10229]\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 2.719144 [    4/10229]\n",
      "loss: 3.103798 [  404/10229]\n",
      "loss: 0.167820 [  804/10229]\n",
      "loss: 7.317556 [ 1204/10229]\n",
      "loss: 6.059608 [ 1604/10229]\n",
      "loss: 3.282412 [ 2004/10229]\n",
      "loss: 2.270403 [ 2404/10229]\n",
      "loss: 3.482541 [ 2804/10229]\n",
      "loss: 4.137570 [ 3204/10229]\n",
      "loss: 5.945192 [ 3604/10229]\n",
      "loss: 2.039235 [ 4004/10229]\n",
      "loss: 10.699838 [ 4404/10229]\n",
      "loss: 4.870975 [ 4804/10229]\n",
      "loss: 4.120180 [ 5204/10229]\n",
      "loss: 4.055459 [ 5604/10229]\n",
      "loss: 5.750578 [ 6004/10229]\n",
      "loss: 6.687532 [ 6404/10229]\n",
      "loss: 5.234787 [ 6804/10229]\n",
      "loss: 6.642826 [ 7204/10229]\n",
      "loss: 0.666850 [ 7604/10229]\n",
      "loss: 14.871378 [ 8004/10229]\n",
      "loss: 2.590542 [ 8404/10229]\n",
      "loss: 7.201157 [ 8804/10229]\n",
      "loss: 3.072191 [ 9204/10229]\n",
      "loss: 5.889882 [ 9604/10229]\n",
      "loss: 5.621419 [10004/10229]\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 2.319290 [    4/10229]\n",
      "loss: 6.002995 [  404/10229]\n",
      "loss: 0.038970 [  804/10229]\n",
      "loss: 6.646999 [ 1204/10229]\n",
      "loss: 6.757205 [ 1604/10229]\n",
      "loss: 8.288465 [ 2004/10229]\n",
      "loss: 0.542709 [ 2404/10229]\n",
      "loss: 9.304772 [ 2804/10229]\n",
      "loss: 1.911056 [ 3204/10229]\n",
      "loss: 0.021757 [ 3604/10229]\n",
      "loss: 1.971173 [ 4004/10229]\n",
      "loss: 0.816427 [ 4404/10229]\n",
      "loss: 4.482525 [ 4804/10229]\n",
      "loss: 6.570032 [ 5204/10229]\n",
      "loss: 7.427852 [ 5604/10229]\n",
      "loss: 1.556158 [ 6004/10229]\n",
      "loss: 5.674792 [ 6404/10229]\n",
      "loss: 4.466228 [ 6804/10229]\n",
      "loss: 3.020243 [ 7204/10229]\n",
      "loss: 0.005392 [ 7604/10229]\n",
      "loss: 4.960559 [ 8004/10229]\n",
      "loss: 7.369172 [ 8404/10229]\n",
      "loss: 0.534508 [ 8804/10229]\n",
      "loss: 2.331152 [ 9204/10229]\n",
      "loss: 2.944494 [ 9604/10229]\n",
      "loss: 1.161916 [10004/10229]\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.541350 [    4/10229]\n",
      "loss: 3.987455 [  404/10229]\n",
      "loss: 4.711706 [  804/10229]\n",
      "loss: 5.447091 [ 1204/10229]\n",
      "loss: 2.004730 [ 1604/10229]\n",
      "loss: 0.745933 [ 2004/10229]\n",
      "loss: 4.824741 [ 2404/10229]\n",
      "loss: 2.271160 [ 2804/10229]\n",
      "loss: 8.520554 [ 3204/10229]\n",
      "loss: 5.904107 [ 3604/10229]\n",
      "loss: 1.871267 [ 4004/10229]\n",
      "loss: 1.490553 [ 4404/10229]\n",
      "loss: 3.593096 [ 4804/10229]\n",
      "loss: 16.570007 [ 5204/10229]\n",
      "loss: 4.787210 [ 5604/10229]\n",
      "loss: 6.387394 [ 6004/10229]\n",
      "loss: 2.817757 [ 6404/10229]\n",
      "loss: 2.414614 [ 6804/10229]\n",
      "loss: 2.298209 [ 7204/10229]\n",
      "loss: 4.376325 [ 7604/10229]\n",
      "loss: 3.058367 [ 8004/10229]\n",
      "loss: 4.342578 [ 8404/10229]\n",
      "loss: 2.365287 [ 8804/10229]\n",
      "loss: 2.167709 [ 9204/10229]\n",
      "loss: 0.960873 [ 9604/10229]\n",
      "loss: 5.107224 [10004/10229]\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 1.398060 [    4/10229]\n",
      "loss: 1.997346 [  404/10229]\n",
      "loss: 3.749172 [  804/10229]\n",
      "loss: 5.514555 [ 1204/10229]\n",
      "loss: 2.669638 [ 1604/10229]\n",
      "loss: 3.200549 [ 2004/10229]\n",
      "loss: 0.314383 [ 2404/10229]\n",
      "loss: 0.087792 [ 2804/10229]\n",
      "loss: 0.001708 [ 3204/10229]\n",
      "loss: 0.002860 [ 3604/10229]\n",
      "loss: 0.438305 [ 4004/10229]\n",
      "loss: 4.095906 [ 4404/10229]\n",
      "loss: 3.775908 [ 4804/10229]\n",
      "loss: 4.800247 [ 5204/10229]\n",
      "loss: 1.577768 [ 5604/10229]\n",
      "loss: 1.162693 [ 6004/10229]\n",
      "loss: 3.237721 [ 6404/10229]\n",
      "loss: 7.266952 [ 6804/10229]\n",
      "loss: 1.475438 [ 7204/10229]\n",
      "loss: 7.691906 [ 7604/10229]\n",
      "loss: 3.212563 [ 8004/10229]\n",
      "loss: 4.438192 [ 8404/10229]\n",
      "loss: 0.814537 [ 8804/10229]\n",
      "loss: 1.989493 [ 9204/10229]\n",
      "loss: 3.096941 [ 9604/10229]\n",
      "loss: 7.737376 [10004/10229]\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 2.914445 [    4/10229]\n",
      "loss: 2.401805 [  404/10229]\n",
      "loss: 0.000002 [  804/10229]\n",
      "loss: 0.036437 [ 1204/10229]\n",
      "loss: 8.302704 [ 1604/10229]\n",
      "loss: 2.801296 [ 2004/10229]\n",
      "loss: 0.143993 [ 2404/10229]\n",
      "loss: 2.441653 [ 2804/10229]\n",
      "loss: 8.460488 [ 3204/10229]\n",
      "loss: 3.215442 [ 3604/10229]\n",
      "loss: 2.377817 [ 4004/10229]\n",
      "loss: 3.902546 [ 4404/10229]\n",
      "loss: 0.765430 [ 4804/10229]\n",
      "loss: 4.044950 [ 5204/10229]\n",
      "loss: 4.357747 [ 5604/10229]\n",
      "loss: 13.911652 [ 6004/10229]\n",
      "loss: 1.802734 [ 6404/10229]\n",
      "loss: 3.164579 [ 6804/10229]\n",
      "loss: 6.466314 [ 7204/10229]\n",
      "loss: 0.991688 [ 7604/10229]\n",
      "loss: 0.555239 [ 8004/10229]\n",
      "loss: 6.102103 [ 8404/10229]\n",
      "loss: 0.272703 [ 8804/10229]\n",
      "loss: 1.595906 [ 9204/10229]\n",
      "loss: 2.736830 [ 9604/10229]\n",
      "loss: 6.560843 [10004/10229]\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.014257 [    4/10229]\n",
      "loss: 7.029458 [  404/10229]\n",
      "loss: 7.449990 [  804/10229]\n",
      "loss: 15.595816 [ 1204/10229]\n",
      "loss: 5.592786 [ 1604/10229]\n",
      "loss: 3.313091 [ 2004/10229]\n",
      "loss: 1.763087 [ 2404/10229]\n",
      "loss: 1.066283 [ 2804/10229]\n",
      "loss: 0.833884 [ 3204/10229]\n",
      "loss: 0.999582 [ 3604/10229]\n",
      "loss: 6.617156 [ 4004/10229]\n",
      "loss: 0.592103 [ 4404/10229]\n",
      "loss: 7.990947 [ 4804/10229]\n",
      "loss: 4.674954 [ 5204/10229]\n",
      "loss: 2.503016 [ 5604/10229]\n",
      "loss: 11.502017 [ 6004/10229]\n",
      "loss: 8.251904 [ 6404/10229]\n",
      "loss: 0.908743 [ 6804/10229]\n",
      "loss: 3.252792 [ 7204/10229]\n",
      "loss: 1.752038 [ 7604/10229]\n",
      "loss: 11.697540 [ 8004/10229]\n",
      "loss: 7.383105 [ 8404/10229]\n",
      "loss: 0.693044 [ 8804/10229]\n",
      "loss: 1.241001 [ 9204/10229]\n",
      "loss: 3.719733 [ 9604/10229]\n",
      "loss: 8.518336 [10004/10229]\n",
      "Epoch 16\n",
      "-------------------------------\n",
      "loss: 6.225960 [    4/10229]\n",
      "loss: 1.969999 [  404/10229]\n",
      "loss: 0.577825 [  804/10229]\n",
      "loss: 2.965364 [ 1204/10229]\n",
      "loss: 4.615337 [ 1604/10229]\n",
      "loss: 5.985049 [ 2004/10229]\n",
      "loss: 2.686961 [ 2404/10229]\n",
      "loss: 6.123209 [ 2804/10229]\n",
      "loss: 1.599116 [ 3204/10229]\n",
      "loss: 6.205511 [ 3604/10229]\n",
      "loss: 0.003072 [ 4004/10229]\n",
      "loss: 6.069538 [ 4404/10229]\n",
      "loss: 8.497325 [ 4804/10229]\n",
      "loss: 3.450483 [ 5204/10229]\n",
      "loss: 0.922180 [ 5604/10229]\n",
      "loss: 0.818637 [ 6004/10229]\n",
      "loss: 0.582104 [ 6404/10229]\n",
      "loss: 1.493711 [ 6804/10229]\n",
      "loss: 6.288546 [ 7204/10229]\n",
      "loss: 3.105988 [ 7604/10229]\n",
      "loss: 10.111314 [ 8004/10229]\n",
      "loss: 4.489110 [ 8404/10229]\n",
      "loss: 5.217052 [ 8804/10229]\n",
      "loss: 9.537883 [ 9204/10229]\n",
      "loss: 0.762160 [ 9604/10229]\n",
      "loss: 6.043390 [10004/10229]\n",
      "Epoch 17\n",
      "-------------------------------\n",
      "loss: 0.052353 [    4/10229]\n",
      "loss: 0.484482 [  404/10229]\n",
      "loss: 3.235573 [  804/10229]\n",
      "loss: 0.007133 [ 1204/10229]\n",
      "loss: 0.523747 [ 1604/10229]\n",
      "loss: 0.000973 [ 2004/10229]\n",
      "loss: 0.399121 [ 2404/10229]\n",
      "loss: 0.415106 [ 2804/10229]\n",
      "loss: 0.000269 [ 3204/10229]\n",
      "loss: 0.144806 [ 3604/10229]\n",
      "loss: 2.775783 [ 4004/10229]\n",
      "loss: 5.599613 [ 4404/10229]\n",
      "loss: 1.191285 [ 4804/10229]\n",
      "loss: 8.373297 [ 5204/10229]\n",
      "loss: 0.412565 [ 5604/10229]\n",
      "loss: 6.856809 [ 6004/10229]\n",
      "loss: 0.022126 [ 6404/10229]\n",
      "loss: 0.570722 [ 6804/10229]\n",
      "loss: 2.363504 [ 7204/10229]\n",
      "loss: 5.810434 [ 7604/10229]\n",
      "loss: 2.195136 [ 8004/10229]\n",
      "loss: 0.021273 [ 8404/10229]\n",
      "loss: 4.841268 [ 8804/10229]\n",
      "loss: 7.976016 [ 9204/10229]\n",
      "loss: 4.162832 [ 9604/10229]\n",
      "loss: 3.564899 [10004/10229]\n",
      "Epoch 18\n",
      "-------------------------------\n",
      "loss: 1.319276 [    4/10229]\n",
      "loss: 9.793134 [  404/10229]\n",
      "loss: 0.000001 [  804/10229]\n",
      "loss: 3.579381 [ 1204/10229]\n",
      "loss: 4.850134 [ 1604/10229]\n",
      "loss: 2.207221 [ 2004/10229]\n",
      "loss: 2.064855 [ 2404/10229]\n",
      "loss: 3.208708 [ 2804/10229]\n",
      "loss: 2.327559 [ 3204/10229]\n",
      "loss: 3.080280 [ 3604/10229]\n",
      "loss: 3.741567 [ 4004/10229]\n",
      "loss: 2.917607 [ 4404/10229]\n",
      "loss: 0.003549 [ 4804/10229]\n",
      "loss: 0.261507 [ 5204/10229]\n",
      "loss: 3.713671 [ 5604/10229]\n",
      "loss: 0.395159 [ 6004/10229]\n",
      "loss: 0.518557 [ 6404/10229]\n",
      "loss: 2.159496 [ 6804/10229]\n",
      "loss: 1.387536 [ 7204/10229]\n",
      "loss: 0.163631 [ 7604/10229]\n",
      "loss: 11.639647 [ 8004/10229]\n",
      "loss: 3.493338 [ 8404/10229]\n",
      "loss: 0.045880 [ 8804/10229]\n",
      "loss: 0.008373 [ 9204/10229]\n",
      "loss: 0.000005 [ 9604/10229]\n",
      "loss: 6.665082 [10004/10229]\n",
      "Epoch 19\n",
      "-------------------------------\n",
      "loss: 1.286988 [    4/10229]\n",
      "loss: 0.223263 [  404/10229]\n",
      "loss: 0.033105 [  804/10229]\n",
      "loss: 2.546693 [ 1204/10229]\n",
      "loss: 0.022611 [ 1604/10229]\n",
      "loss: 6.594824 [ 2004/10229]\n",
      "loss: 3.517192 [ 2404/10229]\n",
      "loss: 7.689834 [ 2804/10229]\n",
      "loss: 0.000002 [ 3204/10229]\n",
      "loss: 0.715002 [ 3604/10229]\n",
      "loss: 2.110573 [ 4004/10229]\n",
      "loss: 2.541760 [ 4404/10229]\n",
      "loss: 0.344050 [ 4804/10229]\n",
      "loss: 0.014807 [ 5204/10229]\n",
      "loss: 0.052618 [ 5604/10229]\n",
      "loss: 1.396454 [ 6004/10229]\n",
      "loss: 6.656726 [ 6404/10229]\n",
      "loss: 1.618912 [ 6804/10229]\n",
      "loss: 6.410063 [ 7204/10229]\n",
      "loss: 1.338432 [ 7604/10229]\n",
      "loss: 2.661560 [ 8004/10229]\n",
      "loss: 3.464006 [ 8404/10229]\n",
      "loss: 3.156415 [ 8804/10229]\n",
      "loss: 5.139356 [ 9204/10229]\n",
      "loss: 0.419785 [ 9604/10229]\n",
      "loss: 3.640920 [10004/10229]\n",
      "Epoch 20\n",
      "-------------------------------\n",
      "loss: 1.413413 [    4/10229]\n",
      "loss: 3.527641 [  404/10229]\n",
      "loss: 0.629432 [  804/10229]\n",
      "loss: 2.779826 [ 1204/10229]\n",
      "loss: 4.526201 [ 1604/10229]\n",
      "loss: 16.100502 [ 2004/10229]\n",
      "loss: 5.922233 [ 2404/10229]\n",
      "loss: 7.771948 [ 2804/10229]\n",
      "loss: 0.160078 [ 3204/10229]\n",
      "loss: 1.609838 [ 3604/10229]\n",
      "loss: 0.754892 [ 4004/10229]\n",
      "loss: 1.205942 [ 4404/10229]\n",
      "loss: 3.866335 [ 4804/10229]\n",
      "loss: 0.000935 [ 5204/10229]\n",
      "loss: 4.848194 [ 5604/10229]\n",
      "loss: 2.346935 [ 6004/10229]\n",
      "loss: 4.858677 [ 6404/10229]\n",
      "loss: 0.220080 [ 6804/10229]\n",
      "loss: 2.112135 [ 7204/10229]\n",
      "loss: 0.114536 [ 7604/10229]\n",
      "loss: 0.089411 [ 8004/10229]\n",
      "loss: 3.036187 [ 8404/10229]\n",
      "loss: 1.579242 [ 8804/10229]\n",
      "loss: 6.471193 [ 9204/10229]\n",
      "loss: 0.025957 [ 9604/10229]\n",
      "loss: 1.452483 [10004/10229]\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20 # Set the number of epochs for training\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5599ffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval() # Ensure model is in evaluation mode\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # No gradient calculation needed during evaluation\n",
    "    with torch.no_grad():\n",
    "        for batch_tokens, batch_labels in dataloader:\n",
    "            batch_tokens = batch_tokens.to(device)\n",
    "            batch_labels = batch_labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(batch_tokens)\n",
    "\n",
    "            # Calculate loss (optional for testing, but good for understanding)\n",
    "            loss_fn = nn.CrossEntropyLoss() # Use the same loss function as training\n",
    "            loss = loss_fn(outputs, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Get predictions (the class with the highest probability/logit)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    \n",
    "    # Generate a classification report (precision, recall, f1-score per class)\n",
    "    report = classification_report(all_labels, all_preds, target_names=list(label_to_id.keys()), output_dict=True)\n",
    "    \n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    return avg_loss, accuracy, report, cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1c75b0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results on Training Dataset ---\n",
      "Test Loss: 0.2864\n",
      "Test Accuracy: 0.9203\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score       support\n",
      "FALSE          0.870177  0.957064  0.911555   2003.000000\n",
      "TRUE           0.927536  0.896468  0.911737   1642.000000\n",
      "barely-true    0.962155  0.891795  0.925640   1682.000000\n",
      "half-true      0.929303  0.907187  0.918112   2101.000000\n",
      "mostly-true    0.924365  0.927662  0.926011   1963.000000\n",
      "pants-fire     0.928987  0.952267  0.940483    838.000000\n",
      "accuracy       0.920325  0.920325  0.920325      0.920325\n",
      "macro avg      0.923754  0.922074  0.922256  10229.000000\n",
      "weighted avg   0.921870  0.920325  0.920391  10229.000000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1917   13   20   26   16   11]\n",
      " [  64 1472   11   47   33   15]\n",
      " [  87   16 1500   32   35   12]\n",
      " [  72   36   11 1906   60   16]\n",
      " [  46   44   10   35 1821    7]\n",
      " [  17    6    7    5    5  798]]\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation\n",
    "train_loss, train_accuracy, train_report, train_confusion_matrix = evaluate_model(model, train_dataloader, device=torch.device('cpu'))\n",
    "\n",
    "print(f\"\\n--- Test Results on Training Dataset ---\")\n",
    "print(f\"Test Loss: {train_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {train_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "# Convert dict to string for pretty print\n",
    "print(pd.DataFrame(train_report).transpose())\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(train_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "34e3c332",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# The following code demonstrates how to evaluate a trained TextCNN model on a test dataset using PyTorch.\n",
    "# It sets up a DataLoader for batching and padding, runs the evaluation loop, and prints out key metrics\n",
    "# such as test loss, accuracy, classification report, and confusion matrix. This process helps assess\n",
    "# the model's performance on unseen data and provides insights into its predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f92d761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataLoader ready.\n"
     ]
    }
   ],
   "source": [
    "# Instantiate your dataloader for the test dataset\n",
    "test_batch_size = 8 \n",
    "test_dataloader = DataLoader(test_dataset,\n",
    "                             batch_size=test_batch_size,\n",
    "                             shuffle=False, \n",
    "                             collate_fn=collate_fn)\n",
    "\n",
    "print(\"Test DataLoader ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ddaa186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Test Results ---\n",
      "Test Loss: 11.0489\n",
      "Test Accuracy: 0.2189\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score      support\n",
      "FALSE          0.222362  0.353293  0.272938   501.000000\n",
      "TRUE           0.173585  0.111922  0.136095   411.000000\n",
      "barely-true    0.235955  0.150000  0.183406   420.000000\n",
      "half-true      0.248299  0.277567  0.262118   526.000000\n",
      "mostly-true    0.217391  0.203666  0.210305   491.000000\n",
      "pants-fire     0.153846  0.133971  0.143223   209.000000\n",
      "accuracy       0.218921  0.218921  0.218921     0.218921\n",
      "macro avg      0.208573  0.205070  0.201347  2558.000000\n",
      "weighted avg   0.215538  0.218921  0.211405  2558.000000\n",
      "\n",
      "Confusion Matrix:\n",
      "[[177  57  46 107  81  33]\n",
      " [131  46  29  90  84  31]\n",
      " [126  35  63  99  72  25]\n",
      " [144  52  55 146  98  31]\n",
      " [145  62  49 101 100  34]\n",
      " [ 73  13  25  45  25  28]]\n"
     ]
    }
   ],
   "source": [
    "# Run the evaluation\n",
    "test_loss, test_accuracy, test_report, test_confusion_matrix = evaluate_model(model, test_dataloader, device=torch.device('cpu'))\n",
    "\n",
    "print(f\"\\n--- Test Results ---\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "# Convert dict to string for pretty print\n",
    "print(pd.DataFrame(test_report).transpose())\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(test_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f3482b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'vocab_size': vocab_size,\n",
    "    'embedding_dim': embedding_dim,\n",
    "    'num_classes': num_classes,\n",
    "    'pad_idx': PAD_ID,  \n",
    "    'unk_idx': UNK_ID\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "022c621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to textcnn_model.pth\n"
     ]
    }
   ],
   "source": [
    "# Export the trained model to a file\n",
    "torch.save(model.state_dict(), \"textcnn_model.pth\")\n",
    "print(\"Model exported to textcnn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d70f2d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the word_to_id mapping\n",
    "with open('word_to_id.pkl', 'wb') as f:\n",
    "    pickle.dump(word_to_id, f)\n",
    "# Save the id_to_label mapping\n",
    "with open('id_to_label.pkl', 'wb') as f:\n",
    "    pickle.dump(id_to_label, f)\n",
    "with open('model_args.pkl', 'wb') as fp:\n",
    "    pickle.dump(model_args, fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-classification-v01",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
